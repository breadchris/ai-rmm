<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction on AI RMM</title>
    <link>https://breadchris.github.io/ai-rmm/</link>
    <description>Recent content in Introduction on AI RMM</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language><atom:link href="https://breadchris.github.io/ai-rmm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 1 # Policies, processes, procedures, and practices across the organization related to the mapping, measuring, and managing of AI risks are in place, transparent, and implemented effectively. [@airmf]
Govern 1.1 # Legal and regulatory requirements involving AI are understood, managed, and documented.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 1.2 # The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and practices. [@playbook]
Govern 1.2.1. Define and document the characteristics of trustworthy AI. # Defining and documenting the characteristics of trustworthy AI involves establishing clear guidelines that embody principles such as fairness, transparency, accountability, privacy, and security within AI systems.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 1.3 # Processes, procedures, and practices are in place to determine the needed level of risk management activities based on the organization&amp;rsquo;s risk tolerance. [@playbook]
Govern 1.3.1. Establish an organizational risk tolerance framework.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.4/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 1.4 # The risk management process and its outcomes are established through transparent policies, procedures, and other controls based on organizational risk priorities. [@playbook]
Govern 1.4.1. Establish clear risk management policies. # Establishing clear risk management policies is pivotal for setting the foundation of a robust AI risk management framework within an organization.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.5/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 1.5 # Ongoing monitoring and periodic review of the risk management process and its outcomes are planned and organizational roles and responsibilities clearly defined, including determining the frequency of periodic review. [@playbook]</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.6/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 1.6 # Mechanisms are in place to inventory AI systems and are resourced according to organizational risk priorities. [@playbook]
Govern 1.6.1. Inventory AI systems. # Creating an inventory of AI systems within an organization is a critical first step towards effective AI governance and risk management.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-1.7/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 1.7 # Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that does not increase risks or decrease the organization’s trustworthiness. [@playbook]
Govern 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-2.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-2.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 2 # Accountability structures are in place so that the appropriate teams and individuals are empowered, responsible, and trained for mapping, measuring, and managing AI risks. [@airmf]
Govern 2.1 # Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are documented and are clear to individuals and teams throughout the organization.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-2.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-2.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 2.2 # The organization’s personnel and partners receive AI risk management training to enable them to perform their duties and responsibilities consistent with related policies, procedures, and agreements. [@playbook]
Govern 2.2.1. Develop and Implement a Comprehensive AI Risk Management Training Program.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-2.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-2.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 2.3 # Executive leadership of the organization takes responsibility for decisions about risks associated with AI system development and deployment. [@playbook]
Govern 2.3.1. Establish an AI Risk Management Leadership Council. # To effectively manage risks associated with AI system development and deployment, establish an AI Risk Management Leadership Council comprising key executives and stakeholders.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-3.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-3.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 3 # Workforce diversity, equity, inclusion, and accessibility processes are prioritized in the mapping, measuring, and managing of AI risks throughout the lifecycle. [@airmf]
Govern 3.1 # Decision-making related to mapping, measuring, and managing AI risks throughout the lifecycle is informed by a diverse team (e.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-3.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-3.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 3.2 # Policies and procedures are in place to define and differentiate roles and responsibilities for human-AI configurations and oversight of AI systems. [@playbook]
Govern 3.2.1. Establish Clear Roles and Responsibilities. # To ensure effective oversight of AI systems and human-AI configurations, organizations must establish clear roles and responsibilities for all involved parties.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-4.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-4.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 4 # Organizational teams are committed to a culture that considers and communicates AI risk. [@airmf]
Govern 4.1 # Organizational policies and practices are in place to foster a critical thinking and safety-first mindset in the design, development, deployment, and uses of AI systems to minimize potential negative impacts.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-4.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-4.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 4.2 # Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly. [@playbook]
Govern 4.2.1. Establish a Risk Documentation Process.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-4.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-4.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 4.3 # Organizational practices are in place to enable AI testing, identification of incidents, and information sharing. [@playbook]
Govern 4.3.1. Establish a Comprehensive Testing Strategy. # To establish a comprehensive testing strategy, organizations must define clear objectives and methodologies for evaluating AI systems throughout their development lifecycle.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-5.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-5.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 5 # Processes are in place for robust engagement with relevant AI actors. [@airmf]
Govern 5.1 # Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-5.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-5.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 5.2 # Mechanisms are established to enable the team that developed or deployed AI systems to regularly incorporate adjudicated feedback from relevant AI actors into system design and implementation. [@playbook]
Govern 5.2.1. Establish an Adjudication Process.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-6.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-6.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 6 # Policies and procedures are in place to address AI risks and benefits arising from third-party software and data and other supply chain issues. [@airmf]
Govern 6.1: # Policies and procedures are in place that address AI risks associated with third-party entities, including risks of infringement of a third-party’s intellectual property or other rights.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-6.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/govern/govern-6.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Govern 6.2 # Contingency processes are in place to handle failures or incidents in third-party data or AI systems deemed to be high-risk. [@playbook]
Govern 6.2.1. Identify High-Risk Third-Party Data and AI Systems. # To effectively manage potential failures or incidents in third-party data or AI systems, it&amp;rsquo;s essential to first identify those considered high-risk.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 1 # AI risks based on assessments and other analytical output from the MAP and MEASURE functions are prioritized, responded to, and managed. [@airmf]
Manage 1.1 # A determination is made as to whether the AI system achieves its intended purposes and stated objectives and whether its development or deployment should proceed.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 1.2 # Treatment of documented AI risks is prioritized based on impact, likelihood, and available resources or methods. [@playbook]
Manage 1.2.1. Prioritize Risks Based on Impact and Likelihood. # To effectively manage AI risks, prioritize them based on their impact and likelihood, ensuring that resources are allocated efficiently.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 1.3 # Responses to the AI risks deemed high priority, as identified by the map function, are developed, planned, and documented. Risk response options can include mitigating, transferring, avoiding, or accepting. [@playbook]</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-1.4/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 1.4 # Negative residual risks (defined as the sum of all unmitigated risks) to both downstream acquirers of AI systems and end users are documented. [@playbook]
Manage 1.4.1. Identify and Quantify Residual Risks.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 2 # Strategies to maximize AI benefits and minimize negative impacts are planned, prepared, implemented, documented, and informed by input from relevant AI actors. [@airmf]
Manage 2.1 # Resources required to manage AI risks are taken into account – along with viable non-AI alternative systems, approaches, or methods – to reduce the magnitude or likelihood of potential impacts.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 2.2 # Mechanisms are in place and applied to sustain the value of deployed AI systems. [@playbook]
Manage 2.2.1. Establish Ongoing Monitoring and Evaluation. # Establishing ongoing monitoring and evaluation processes is essential to ensure the continued value and effectiveness of deployed AI systems.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 2.3 # Procedures are followed to respond to and recover from a previously unknown risk when it is identified. [@playbook]
Manage 2.3.1. Establish Incident Response Plan. # Establishing an incident response plan is essential for effectively responding to and recovering from previously unknown risks in AI systems.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-2.4/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 2.4 # Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or deactivate AI systems that demonstrate performance or outcomes inconsistent with intended use. [@playbook]
Manage 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-3.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-3.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 3 # AI risks and benefits from third-party entities are managed. [@airmf]
Manage 3.1 # AI risks and benefits from third-party resources are regularly monitored, and risk controls are applied and documented. [@playbook]</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-3.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-3.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 3.2 # Pre-trained models which are used for development are monitored as part of AI system regular monitoring and maintenance. [@playbook]
Manage 3.2.1. Establish Pre-trained Model Inventory and Tracking. # Establishing a pre-trained model inventory and tracking system involves cataloging and monitoring the usage of pre-trained models utilized in the development of AI systems.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-4.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-4.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 4 # Risk treatments, including response and recovery, and communication plans for the identified and measured AI risks are documented and monitored regularly. [@airmf]
Manage 4.1 # Post-deployment AI system monitoring plans are implemented, including mechanisms for capturing and evaluating input from users and other relevant AI actors, appeal and override, decommissioning, incident response, recovery, and change management.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-4.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-4.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 4.2 # Measurable activities for continual improvements are integrated into AI system updates and include regular engagement with interested parties, including relevant AI actors. [@playbook]
Manage 4.2.1. Integrate Measurable Improvement Goals. # To enhance AI system performance and ensure continual improvement, it&amp;rsquo;s essential to integrate measurable improvement goals into system updates.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-4.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/manage/manage-4.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Manage 4.3 # Incidents and errors are communicated to relevant AI actors, including affected communities. Processes for tracking, responding to, and recovering from incidents and errors are followed and documented. [@playbook]
Manage 4.3.1. Establish a Clear Incident Reporting Process.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 1 # Context is established and understood. [@airmf]
Map 1.1 # Intended purposes, potentially beneficial uses, context-specific laws, norms and expectations, and prospective settings in which the AI system will be deployed are understood and documented.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 1.2 # Interdisciplinary AI actors, competencies, skills, and capacities for establishing context reflect demographic diversity and broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 1.3 # The organization’s mission and relevant goals for AI technology are understood and documented. [@playbook]
Map 1.3.1. Articulate a Clear and Comprehensive Mission Statement. # A well-crafted mission statement serves as the guiding beacon for the organization&amp;rsquo;s AI initiatives, encapsulating its core values, objectives, and ethical considerations.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.4/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 1.4 # The business value or context of business use has been clearly defined or – in the case of assessing existing AI systems – re-evaluated. [@playbook]
Map 1.4.1. Clearly Define the Business Value of AI Systems.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.5/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 1.5 # Organizational risk tolerances are determined and documented. [@playbook]
Map 1.5.1. Establish an Organizational Risk Tolerance Framework. # Establishing an organizational risk tolerance framework is essential for effectively managing risks associated with AI implementation.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-1.6/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 1.6 # System requirements (e.g., “the system shall respect the privacy of its users”) are elicited from and understood by relevant AI actors. Design decisions take socio-technical implications into account to address AI risks.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-2.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-2.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 2 # Categorization of the AI system is performed. [@airmf]
Map 2.1 # The specific tasks and methods used to implement the tasks that the AI system will support are defined (e.g., classifiers, generative models, recommenders).</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-2.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-2.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 2.2 # Information about the AI system’s knowledge limits and how system output may be utilized and overseen by humans is documented. Documentation provides sufficient information to assist relevant AI actors when making decisions and taking subsequent actions.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-2.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-2.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 2.3 # Scientific integrity and TEVV considerations are identified and documented, including those related to experimental design, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct validation. [@playbook]
Map 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 3 # AI capabilities, targeted usage, goals, and expected benefits and costs compared with appropriate benchmarks are understood. [@airmf]
Map 3.1 # Potential benefits of intended AI system functionality and performance are examined and documented.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 3.2 # Potential costs, including non-monetary costs, which result from expected or realized AI errors or system functionality and trustworthiness – as connected to organizational risk tolerance – are examined and documented. [@playbook]</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 3.3 # Targeted application scope is specified and documented based on the system’s capability, established context, and AI system categorization. [@playbook]
Map 3.3.1. Clearly Define AI System Capabilities. # Clearly defining AI system capabilities involves thoroughly outlining the range of functions, tasks, and operations that the AI system is designed to perform.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.4/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 3.4 # Processes for operator and practitioner proficiency with AI system performance and trustworthiness – and relevant technical standards and certifications – are defined, assessed, and documented. [@playbook]
Map 3.4.1. Establish Clear Proficiency Requirements.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-3.5/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 3.5 # Processes for human oversight are defined, assessed, and documented in accordance with organizational policies from the govern function. [@playbook]
Map 3.5.1. Establish Human Oversight Roles and Responsibilities. # To establish human oversight roles and responsibilities within AI systems, organizations must define clear guidelines and assign specific tasks to individuals responsible for monitoring and managing AI operations.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-4.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-4.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 4 # Risks and benefits are mapped for all components of the AI system including third-party software and data. [@airmf]
Map 4.1 # Approaches for mapping AI technology and legal risks of its components – including the use of third-party data or software – are in place, followed, and documented, as are risks of infringement of a third party’s intellectual property or other rights.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-4.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-4.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 4.2 # Internal risk controls for components of the AI system, including third-party AI technologies, are identified and documented. [@playbook]
Map 4.2.1. Identify and Assess Internal Risks for AI Components. # To effectively manage the internal risks associated with AI components, it&amp;rsquo;s crucial to conduct a comprehensive identification and assessment process.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-5.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-5.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 5 # Impacts to individuals, groups, communities, organizations, and society are characterized. [@airmf]
Map 5.1 # Likelihood and magnitude of each identified impact (both potentially beneficial and harmful) based on expected use, past uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed the AI system, or other data are identified and documented.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/map/map-5.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/map/map-5.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Map 5.2 # Practices and personnel for supporting regular engagement with relevant AI actors and integrating feedback about positive, negative, and unanticipated impacts are in place and documented. [@playbook]
Map 5.2.1. Establish a Mechanism for Regular Engagement.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-1.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-1.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 1 # Appropriate methods and metrics are identified and applied. [@airmf]
Measure 1.1 # Approaches and metrics for measurement of AI risks enumerated during the map function are selected for implementation starting with the most significant AI risks.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-1.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-1.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 1.2 # Appropriateness of AI metrics and effectiveness of existing controls are regularly assessed and updated, including reports of errors and potential impacts on affected communities. [@playbook]
Measure 1.2.1. Regularly Evaluate Measurement Approach Relevance.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-1.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-1.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 1.3 # Internal experts who did not serve as front-line developers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts, users, AI actors external to the team that developed or deployed the AI system, and affected communities are consulted in support of assessments as necessary per organizational risk tolerance.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2 # AI systems are evaluated for trustworthy characteristics. [@airmf]
Measure 2.1 # Test sets, metrics, and details about the tools used during Test &amp;amp; Evaluation, Validation &amp;amp; Verification (TEVV) are documented. [@playbook]</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.10/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.10/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.10 # Privacy risk of the AI system – as identified in the map function – is examined and documented. [@playbook]
Measure 2.10.1. Identify and Assess Privacy Risks. # Identifying and assessing privacy risks in AI systems is a crucial step in safeguarding user data and maintaining trust in AI technologies.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.11/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.11/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.11 # Fairness and bias – as identified in the map function – are evaluated and results are documented. [@playbook]
Measure 2.11.1. Identify and Assess Fairness and Bias Concerns. # Identifying and assessing fairness and bias concerns within AI systems are critical steps towards ensuring ethical and equitable AI practices.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.12/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.12/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.12 # Environmental impact and sustainability of AI model training and management activities – as identified in the map function – are assessed and documented. [@playbook]
Measure 2.12.1. Identify and Assess Environmental Impact.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.13/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.13/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.13 # Effectiveness of the employed TEVV metrics and processes in the measure function are evaluated and documented. [@playbook]
Measure 2.13.1. Evaluate TEVV Metric Effectiveness. # Evaluating the effectiveness of TEVV (Trustworthiness, Explainability, Validity, and Value) metrics is crucial for ensuring that the assessment processes in place accurately reflect the AI system&amp;rsquo;s performance and reliability.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.2 # Evaluations involving human subjects meet applicable requirements (including human subject protection) and are representative of the relevant population. [@playbook]
Measure 2.2.1. Design and Plan Human-Subject Evaluations. # Evaluating AI systems with human subjects necessitates meticulous planning and design to ensure ethical standards and representativeness.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.3 # AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for conditions similar to deployment setting(s). Measures are documented. [@playbook]
Measure 2.3.1. Establish Performance or Assurance Criteria. # To set the foundation for evaluating AI systems in environments akin to their intended use, it&amp;rsquo;s crucial to define clear and specific performance or assurance criteria.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.4/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.4 # The functionality and behavior of the AI system and its components – as identified in the map function – are monitored when in production. [@playbook]
Measure 2.4.1. Establish Monitoring Requirements and Objectives.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.5/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.5 # The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed are documented. [@playbook]
Measure 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.6/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.6 # The AI system is evaluated regularly for safety risks – as identified in the map function. The AI system to be deployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if made to operate beyond its knowledge limits.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.7/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.7 # AI system security and resilience – as identified in the map function – are evaluated and documented. [@playbook]
Measure 2.7.1. Establish a Security and Resilience Evaluation Framework. # Establishing a comprehensive framework for evaluating the security and resilience of AI systems is essential in safeguarding against potential threats and vulnerabilities.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.8/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.8 # Risks associated with transparency and accountability – as identified in the map function – are examined and documented. [@playbook]
Measure 2.8.1. Identify Transparency and Accountability Concerns. # Identifying and addressing concerns related to transparency and accountability is critical in the development and deployment of AI systems.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-2.9/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 2.9 # The AI model is explained, validated, and documented, and AI system output is interpreted within its context – as identified in the map function – to inform responsible use and governance.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-3.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-3.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 3 # Mechanisms for tracking identified AI risks over time are in place. [@airmf]
Measure 3.1 # Approaches, personnel, and documentation are in place to regularly identify and track existing, unanticipated, and emergent AI risks based on factors such as intended and actual performance in deployed contexts.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-3.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-3.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 3.2 # Risk tracking approaches are considered for settings where AI risks are difficult to assess using currently available measurement techniques or where metrics are not yet available. [@playbook]
Measure 3.2.1. Recognize Risk Measurement Limitations.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-3.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-3.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 3.3 # Feedback processes for end users and impacted communities to report problems and appeal system outcomes are established and integrated into AI system evaluation metrics. [@playbook]
Measure 3.3.1. Establish Feedback Mechanisms for End Users and Impacted Communities.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-4.1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-4.1/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 4 # Feedback about efficacy of measurement is gathered and assessed. [@airmf]
Measure 4.1 # Measurement approaches for identifying AI risks are connected to deployment context(s) and informed through consultation with domain experts and other end users.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-4.2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-4.2/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 4.2 # Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are informed by input from domain experts and relevant AI actors to validate whether the system is performing consistently as intended.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-4.3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://breadchris.github.io/ai-rmm/docs/framework/measure/measure-4.3/</guid>
      <description>//: # (Copyright (C) 2024 RiskFrame.ai https://www.riskframe.ai https://github.com/riskframe/ai-rmm) //: # (SOFTWARE LICENSE) //: # (This file is part of AI-RMM, which is distributed under GNU General Public License V3. See LICENSE.txt to get a full copy.)
Measure 4.3 # Measurable performance improvements or declines based on consultations with relevant AI actors, including affected communities, and field data about context-relevant risks and trustworthiness characteristics are identified and documented. [@playbook]
Measure 4.</description>
    </item>
    
  </channel>
</rss>
